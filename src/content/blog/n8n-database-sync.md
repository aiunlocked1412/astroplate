---
title: "n8n Database Sync: ‡∏ã‡∏¥‡∏á‡∏Ñ‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏•‡∏≤‡∏¢ Database ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ Real-time"
meta_title: "n8n Database Synchronization | ‡∏ã‡∏¥‡∏á‡∏Ñ‡πå Database ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ Real-time"
description: "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö Database Sync ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢ n8n ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° MySQL, PostgreSQL, MongoDB, Google Sheets, Airtable ‡∏ã‡∏¥‡∏á‡∏Ñ‡πå‡πÅ‡∏ö‡∏ö real-time ‡∏´‡∏£‡∏∑‡∏≠ scheduled"
date: 2025-10-23T03:00:00Z
image: "/images/blog-default.svg"
categories: ["n8n", "Database", "Automation"]
author: "AI Unlocked Team"
tags: ["n8n", "database sync", "MySQL", "PostgreSQL", "MongoDB", "automation", "‡∏Ñ‡∏≠‡∏£‡πå‡∏™ n8n"]
draft: false
---

# n8n Database Sync: ‡∏ã‡∏¥‡∏á‡∏Ñ‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏•‡∏≤‡∏¢ Database ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ Real-time

‡∏Å‡∏≤‡∏£‡∏ã‡∏¥‡∏á‡∏Ñ‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á databases ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡πâ‡∏≤‡∏ó‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£ ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô ‡πÄ‡∏ä‡πà‡∏ô **Production Database**, **Analytics Database**, **CRM**, **Google Sheets** ‡πÅ‡∏•‡∏∞ **Data Warehouse**

‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ manual sync ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô scripts ‡πÄ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏°‡∏≤‡∏Å ‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™ error ‡∏™‡∏π‡∏á ‡πÅ‡∏•‡∏∞‡∏¢‡∏≤‡∏Å maintain

‡∏î‡πâ‡∏ß‡∏¢ **n8n** ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö **Database Synchronization** ‡∏ó‡∏µ‡πà:
- Sync ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÅ‡∏ö‡∏ö real-time ‡∏´‡∏£‡∏∑‡∏≠ scheduled
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö MySQL, PostgreSQL, MongoDB, Airtable, Google Sheets
- Two-way sync ‡∏´‡∏£‡∏∑‡∏≠ one-way sync
- Handle conflicts ‡πÅ‡∏•‡∏∞ errors
- Transform data ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á sync

‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á database sync workflows ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á

## ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç

- [‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏ã‡∏¥‡∏á‡∏Ñ‡πå Database?](#why-sync)
- [Databases ‡∏ó‡∏µ‡πà n8n ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö](#supported-databases)
- [Sync Strategies](#sync-strategies)
- [Workflow 1: MySQL ‚Üí PostgreSQL Sync](#mysql-postgres)
- [Workflow 2: MongoDB ‚Üí Google Sheets](#mongodb-sheets)
- [Workflow 3: Airtable ‚Üî Database Two-way Sync](#airtable-twoway)
- [Workflow 4: Multi-database ETL Pipeline](#multi-db-etl)
- [Real-time vs Scheduled Sync](#realtime-vs-scheduled)
- [Conflict Resolution](#conflict-resolution)
- [Performance Optimization](#performance)
- [Monitoring & Error Handling](#monitoring)
- [Security Best Practices](#security)
- [‡∏Å‡∏£‡∏ì‡∏µ‡∏®‡∏∂‡∏Å‡∏©‡∏≤: E-commerce Platform](#case-study)
- [FAQ](#faq)
- [‡∏™‡∏£‡∏∏‡∏õ](#conclusion)

## ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏ã‡∏¥‡∏á‡∏Ñ‡πå Database? {#why-sync}

### Use Cases ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ

**1. Production ‚Üí Analytics**
```
MySQL (Production DB)
    ‚Üì sync
PostgreSQL (Data Warehouse)
    ‚Üì analyze
BI Tools (Tableau, Metabase)
```

**2. Legacy ‚Üí Modern System**
```
Old System DB
    ‚Üì migrate gradually
New Cloud DB
```

**3. Multi-region Sync**
```
DB Asia ‚Üí DB US ‚Üí DB Europe
(for low latency access)
```

**4. Data Consolidation**
```
Shopify DB + Salesforce + Google Analytics
    ‚Üì sync all
Central Data Lake
```

**5. Backup & Disaster Recovery**
```
Primary DB ‚Üí Backup DB (real-time)
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà Sync

‚ùå **Data silos** - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏£‡∏∞‡∏à‡∏±‡∏î ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
‚ùå **Manual work** - export/import ‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠ ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏°‡∏≤‡∏Å
‚ùå **Outdated data** - analytics ‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤
‚ùå **Errors** - manual process ‡∏°‡∏µ human errors
‚ùå **Scalability issues** - ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö data ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô

### ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á Auto Sync

‚úÖ **Real-time data** - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏™‡∏°‡∏≠
‚úÖ **Single source of truth** - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà
‚úÖ **Save time** - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á manual sync
‚úÖ **Reliability** - error handling ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
‚úÖ **Scalability** - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö data ‡πÇ‡∏ï‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏î‡πâ

## Databases ‡∏ó‡∏µ‡πà n8n ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö {#supported-databases}

### SQL Databases

**1. PostgreSQL**
- n8n Node: ‚úÖ Official
- Features: Full CRUD, transactions
- Use case: Data warehouse, modern apps

**2. MySQL/MariaDB**
- n8n Node: ‚úÖ Official
- Features: Full CRUD
- Use case: Web apps, e-commerce

**3. Microsoft SQL Server**
- n8n Node: ‚úÖ Official
- Features: Full support
- Use case: Enterprise apps

**4. SQLite**
- n8n Node: ‚ö†Ô∏è Via HTTP/custom
- Features: Limited
- Use case: Local/embedded apps

### NoSQL Databases

**1. MongoDB**
- n8n Node: ‚úÖ Official
- Features: Full CRUD, aggregation
- Use case: Flexible schema, big data

**2. Redis**
- n8n Node: ‚úÖ Official
- Features: Key-value operations
- Use case: Caching, sessions

**3. Firebase/Firestore**
- n8n Node: ‚ö†Ô∏è Via HTTP
- Features: Real-time updates
- Use case: Mobile apps

### Cloud/Spreadsheet DBs

**1. Google Sheets**
- n8n Node: ‚úÖ Official
- Features: Full CRUD
- Use case: Non-technical users, reporting

**2. Airtable**
- n8n Node: ‚úÖ Official
- Features: Full CRUD, rich data types
- Use case: Flexible databases

**3. Notion**
- n8n Node: ‚úÖ Official
- Features: Database pages
- Use case: Internal wikis, CMS

### Data Warehouses

**1. Snowflake**
- n8n Node: ‚ö†Ô∏è Via HTTP
- Features: SQL queries
- Use case: Big data analytics

**2. BigQuery**
- n8n Node: ‚úÖ Official
- Features: SQL queries, large datasets
- Use case: Google Cloud analytics

**3. Supabase**
- n8n Node: ‚úÖ Official (PostgreSQL-based)
- Features: Full PostgreSQL support
- Use case: Modern apps with real-time

## Sync Strategies {#sync-strategies}

### 1. Full Sync (Simple but Slow)

```javascript
// ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà sync ‚Üí ‡∏•‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‚Üí insert ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

// Pros:
‚úÖ ‡∏á‡πà‡∏≤‡∏¢ ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å
‚úÖ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á track changes

// Cons:
‚ùå ‡∏ä‡πâ‡∏≤ (‡∏ñ‡πâ‡∏≤ data ‡πÄ‡∏¢‡∏≠‡∏∞)
‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö real-time

// Use case:
- Small datasets (< 10,000 rows)
- Overnight batch sync
```

### 2. Incremental Sync (Efficient)

```javascript
// Sync ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ records ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô (new, updated, deleted)

// Track changes by:
- `updated_at` timestamp
- `version` number
- Database triggers (log changes)

// Pros:
‚úÖ ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å
‚úÖ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö real-time
‚úÖ ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î resources

// Cons:
‚ö†Ô∏è ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏ß‡πà‡∏≤
‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ change tracking

// Use case:
- Large datasets
- Real-time sync
- High-frequency updates
```

### 3. Event-driven Sync (Real-time)

```javascript
// Database trigger ‚Üí Webhook ‚Üí n8n ‚Üí Sync

// Example:
MySQL Trigger on INSERT/UPDATE/DELETE
    ‚Üì
Call Webhook
    ‚Üì
n8n receives webhook
    ‚Üì
Sync to destination DB

// Pros:
‚úÖ Real-time ‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î
‚úÖ Sync ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô

// Cons:
‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á triggers ‡πÉ‡∏ô source DB
‚ùå Network dependency

// Use case:
- Critical real-time data
- Low-latency requirements
```

### 4. CDC (Change Data Capture)

```javascript
// ‡∏≠‡πà‡∏≤‡∏ô database transaction logs

// Tools:
- Debezium (for MySQL, PostgreSQL)
- AWS DMS
- Kafka Connect

// Pros:
‚úÖ Real-time without triggers
‚úÖ ‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö source DB performance

// Cons:
‚ùå ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô setup
‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ external tools

// Use case:
- Enterprise-scale
- Multiple consumers
```

## Workflow 1: MySQL ‚Üí PostgreSQL Sync {#mysql-postgres}

### Scenario: Sync production MySQL to analytics PostgreSQL

**Architecture:**
```
MySQL (Production)
    ‚Üì every 5 minutes
n8n Workflow
    ‚Üì incremental sync
PostgreSQL (Analytics)
```

### Implementation

**1. Schedule Trigger**

```javascript
// Cron: Every 5 minutes
Schedule Trigger:
  Mode: Custom
  Cron Expression: */5 * * * *
```

**2. Get Last Sync Time**

```javascript
// PostgreSQL Node - Get last sync timestamp
Operation: Execute Query
Query:
SELECT MAX(last_sync_at) as last_sync
FROM sync_metadata
WHERE source = 'mysql_products'
```

**3. Query MySQL for New/Updated Records**

```javascript
// MySQL Node
Operation: Execute Query
Query:
SELECT *
FROM products
WHERE updated_at > :lastSync
ORDER BY updated_at ASC
LIMIT 1000

Parameters:
  lastSync: {{ $json.last_sync || '1970-01-01' }}
```

**4. Transform Data (if needed)**

```javascript
// Code Node - Transform MySQL ‚Üí PostgreSQL format
const items = $input.all();

const transformed = items.map(item => {
  return {
    json: {
      id: item.json.id,
      name: item.json.name,
      // MySQL TINYINT(1) ‚Üí PostgreSQL BOOLEAN
      is_active: item.json.is_active === 1,
      // MySQL DECIMAL ‚Üí PostgreSQL NUMERIC
      price: parseFloat(item.json.price),
      // Format datetime
      created_at: new Date(item.json.created_at).toISOString(),
      updated_at: new Date(item.json.updated_at).toISOString()
    }
  };
});

return transformed;
```

**5. Upsert to PostgreSQL**

```javascript
// PostgreSQL Node
Operation: Execute Query
Query:
INSERT INTO products (id, name, is_active, price, created_at, updated_at)
VALUES (:id, :name, :is_active, :price, :created_at, :updated_at)
ON CONFLICT (id) DO UPDATE SET
  name = EXCLUDED.name,
  is_active = EXCLUDED.is_active,
  price = EXCLUDED.price,
  updated_at = EXCLUDED.updated_at

// Run in batch (1000 rows at a time)
```

**6. Update Sync Metadata**

```javascript
// PostgreSQL Node
Operation: Execute Query
Query:
INSERT INTO sync_metadata (source, last_sync_at, records_synced)
VALUES ('mysql_products', NOW(), :recordCount)

Parameters:
  recordCount: {{ $items().length }}
```

### Handle Deletes

```javascript
// Soft delete strategy:

// MySQL: has `deleted_at` column
SELECT * FROM products WHERE deleted_at IS NOT NULL AND deleted_at > :lastSync

// PostgreSQL: mark as deleted
UPDATE products SET deleted_at = :deleted_at WHERE id = :id

// OR Hard delete:
DELETE FROM products WHERE id = :id
```

## Workflow 2: MongoDB ‚Üí Google Sheets {#mongodb-sheets}

### Scenario: Sync MongoDB orders to Google Sheets for business users

**1. MongoDB Node - Get New Orders**

```javascript
// MongoDB Node
Operation: Find
Collection: orders
Query:
{
  "created_at": {
    "$gt": "{{ $json.lastSync }}"
  }
}
Limit: 100
Sort: { "created_at": 1 }
```

**2. Transform MongoDB ‚Üí Sheets Format**

```javascript
// Code Node
const orders = $input.all();

const sheetsData = orders.map(order => {
  return {
    json: {
      'Order ID': order.json._id.toString(),
      'Customer': order.json.customer.name,
      'Email': order.json.customer.email,
      'Total': order.json.total,
      'Status': order.json.status,
      'Items Count': order.json.items.length,
      'Created At': new Date(order.json.created_at).toLocaleString('th-TH'),
      // Flatten nested array
      'Products': order.json.items.map(i => i.name).join(', ')
    }
  };
});

return sheetsData;
```

**3. Append to Google Sheets**

```javascript
// Google Sheets Node
Operation: Append Row
Spreadsheet: Order Dashboard
Sheet: Orders
Data Mode: Define Below

// Map fields:
'Order ID': {{ $json['Order ID'] }}
'Customer': {{ $json.Customer }}
'Email': {{ $json.Email }}
...
```

**4. Alternative: Update if Exists**

```javascript
// For updating existing rows:

// Step 1: Search for existing row
Google Sheets - Lookup
Column: Order ID
Value: {{ $json['Order ID'] }}

// Step 2: IF node
{{ $json.rowNumber !== null }}

// Step 3a: Update existing row
Google Sheets - Update Row
Row Number: {{ $json.rowNumber }}

// Step 3b: Append new row
Google Sheets - Append Row
```

## Workflow 3: Airtable ‚Üî Database Two-way Sync {#airtable-twoway}

### Scenario: Bi-directional sync between Airtable (used by marketing) and PostgreSQL (used by dev)

**Challenge:** Changes can happen on both sides

### Solution: Last-Write-Wins Strategy

**1. Track Modified Time**

```javascript
// Both databases need:
- id (primary key)
- updated_at (timestamp)
- checksum (optional, for conflict detection)
```

**2. Airtable ‚Üí PostgreSQL**

```javascript
// Webhook Trigger from Airtable
// (Use Airtable Automation to call webhook on record update)

Webhook Trigger
    ‚Üì
PostgreSQL - Check if record exists
    ‚Üì
IF {{ $json.exists }}
    ‚Üì
  Compare timestamps:
  IF Airtable.updated_at > PostgreSQL.updated_at
      ‚Üí Update PostgreSQL
  ELSE
      ‚Üí Skip (PostgreSQL is newer)
ELSE
    ‚Üí Insert to PostgreSQL
```

**3. PostgreSQL ‚Üí Airtable**

```javascript
// Schedule Trigger (every 5 min)

Schedule Trigger
    ‚Üì
PostgreSQL - Get records updated in last 5 min
    ‚Üì
For each record:
  Airtable - Search by ID
    ‚Üì
  IF found AND PostgreSQL.updated_at > Airtable.updated_at
      ‚Üí Update Airtable
  ELSE IF not found
      ‚Üí Create in Airtable
  ELSE
      ‚Üí Skip
```

**4. Conflict Detection**

```javascript
// Code Node - Detect conflicts
const conflicts = [];

items.forEach(item => {
  const airtableTime = new Date(item.json.airtable_updated_at);
  const postgresTime = new Date(item.json.postgres_updated_at);
  const timeDiff = Math.abs(airtableTime - postgresTime);

  // If both updated within 1 minute ‚Üí potential conflict
  if (timeDiff < 60000) {
    conflicts.push({
      id: item.json.id,
      airtable_value: item.json.airtable_value,
      postgres_value: item.json.postgres_value,
      airtable_updated: airtableTime,
      postgres_updated: postgresTime
    });
  }
});

// Alert team if conflicts
if (conflicts.length > 0) {
  sendSlackAlert(`‚ö†Ô∏è ${conflicts.length} sync conflicts detected!`);
}
```

## Workflow 4: Multi-database ETL Pipeline {#multi-db-etl}

### Scenario: Consolidate data from multiple sources to data warehouse

**Sources:**
- MySQL (orders)
- MongoDB (user behavior)
- Google Sheets (marketing campaigns)
- Salesforce (CRM)

**Destination:**
- PostgreSQL Data Warehouse

### ETL Workflow

**Extract:**

```javascript
// Parallel extraction (run all at once)

// MySQL Node - Extract orders
MySQL - SELECT * FROM orders WHERE created_at > :lastSync

// MongoDB Node - Extract events
MongoDB - Find events where timestamp > lastSync

// Google Sheets Node - Get campaigns
Sheets - Read Sheet: Campaigns

// Salesforce Node - Get leads
Salesforce - Get Leads updated since lastSync
```

**Transform:**

```javascript
// Code Node - Standardize format
const standardizeOrders = (mysqlOrders) => {
  return mysqlOrders.map(order => ({
    source: 'mysql',
    type: 'order',
    id: `order_${order.id}`,
    user_id: order.customer_id,
    amount: parseFloat(order.total),
    timestamp: new Date(order.created_at),
    metadata: {
      status: order.status,
      items_count: order.items_count
    }
  }));
};

const standardizeEvents = (mongoEvents) => {
  return mongoEvents.map(event => ({
    source: 'mongodb',
    type: 'event',
    id: `event_${event._id}`,
    user_id: event.userId,
    event_name: event.name,
    timestamp: new Date(event.timestamp),
    metadata: event.properties
  }));
};

// Merge all sources
const allData = [
  ...standardizeOrders($items('mysql')),
  ...standardizeEvents($items('mongodb')),
  ...standardizeCampaigns($items('sheets')),
  ...standardizeLeads($items('salesforce'))
];

return allData;
```

**Load:**

```javascript
// PostgreSQL Node - Bulk insert
Operation: Insert
Table: fact_events

// Use COPY for large datasets (faster than INSERT)
Operation: Execute Query
Query:
COPY fact_events (source, type, id, user_id, amount, timestamp, metadata)
FROM STDIN WITH CSV

// Batch insert (1000 rows at a time)
const batches = chunkArray(allData, 1000);
batches.forEach(batch => insertBatch(batch));
```

**Schedule:**

```
Daily ETL: 2 AM
    ‚Üì
Extract (parallel)
    ‚Üì
Transform
    ‚Üì
Validate data quality
    ‚Üì
Load to warehouse
    ‚Üì
Update materialized views
    ‚Üì
Send success notification
```

## Real-time vs Scheduled Sync {#realtime-vs-scheduled}

### Real-time Sync

**Implementation:**

```javascript
// Option 1: Database Triggers ‚Üí Webhook
CREATE TRIGGER products_updated
AFTER UPDATE ON products
FOR EACH ROW
BEGIN
  -- Call n8n webhook
  INSERT INTO webhook_queue (url, data)
  VALUES (
    'https://n8n.yourdomain.com/webhook/sync',
    JSON_OBJECT('id', NEW.id, 'action', 'update')
  );
END;

// Option 2: App-level webhook
// In your app code:
afterUpdate('products', (record) => {
  fetch('https://n8n.yourdomain.com/webhook/sync', {
    method: 'POST',
    body: JSON.stringify(record)
  });
});

// Option 3: CDC tools
// Debezium ‚Üí Kafka ‚Üí n8n webhook
```

**Pros:**
‚úÖ Latency ‡∏ï‡πà‡∏≥‡∏°‡∏≤‡∏Å (< 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
‚úÖ Data ‡∏™‡∏î‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏™‡∏°‡∏≠
‚úÖ Efficient (sync ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô)

**Cons:**
‚ùå Complex setup
‚ùå Network dependent
‚ùå Higher load on source DB

### Scheduled Sync

**Implementation:**

```javascript
// Cron schedules:

// Every 5 minutes
Schedule: */5 * * * *

// Every hour
Schedule: 0 * * * *

// Every night at 2 AM
Schedule: 0 2 * * *

// Every Monday at 6 AM
Schedule: 0 6 * * 1
```

**Pros:**
‚úÖ Simple setup
‚úÖ Predictable load
‚úÖ Easier to debug

**Cons:**
‚ùå Data latency (‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö schedule)
‚ùå ‡∏≠‡∏≤‡∏à sync ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥ (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ changes)

### Hybrid Approach (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)

```javascript
// Critical data: Real-time
orders, payments ‚Üí Real-time webhook sync

// Analytics data: Scheduled
user_stats, reports ‚Üí Hourly sync

// Large datasets: Overnight
full_product_catalog ‚Üí Daily sync at 2 AM
```

## Conflict Resolution {#conflict-resolution}

### Conflict Scenarios

**1. Same Record Updated on Both Sides**

```javascript
// Example:
// Airtable: Product price = 100 (updated at 10:00:30)
// Database: Product price = 120 (updated at 10:00:35)

// Which one wins?
```

**Strategies:**

**A. Last-Write-Wins**
```javascript
// Compare timestamps, newer wins
if (source1.updated_at > source2.updated_at) {
  use(source1);
} else {
  use(source2);
}

// Pros: Simple
// Cons: May lose changes
```

**B. Source-Priority**
```javascript
// Designated "master" source always wins
if (source === 'database') {
  use(database_value); // Database is master
} else {
  skip();
}

// Pros: Clear ownership
// Cons: One-way sync effectively
```

**C. Manual Resolution**
```javascript
// Detect conflict ‚Üí Alert human
if (detectConflict()) {
  sendSlackAlert({
    message: 'Conflict detected!',
    record_id: id,
    source1_value: value1,
    source2_value: value2,
    actions: [
      'Use Source 1',
      'Use Source 2',
      'Merge'
    ]
  });

  waitForUserDecision();
}

// Pros: Accurate
// Cons: Slow, manual
```

**D. Field-level Merge**
```javascript
// Merge non-conflicting fields
const merged = {
  id: record.id,
  name: source1.updated_at > source2.updated_at ? source1.name : source2.name,
  price: source1.price_updated_at > source2.price_updated_at ? source1.price : source2.price,
  stock: source1.stock // Always from source1 (master for stock)
};

// Pros: Least data loss
// Cons: Complex logic
```

### Implementation Example

```javascript
// Code Node - Conflict Resolution
const resolveConflict = (source1, source2, strategy = 'last-write-wins') => {
  switch (strategy) {
    case 'last-write-wins':
      return source1.updated_at > source2.updated_at ? source1 : source2;

    case 'source-priority':
      return source1.source === 'master' ? source1 : source2;

    case 'merge':
      return {
        ...source2,
        ...Object.keys(source1).reduce((acc, key) => {
          if (source1[key + '_updated_at'] > source2[key + '_updated_at']) {
            acc[key] = source1[key];
          }
          return acc;
        }, {})
      };

    default:
      throw new Error('Unknown strategy');
  }
};

const result = resolveConflict($items('db')[0], $items('airtable')[0], 'last-write-wins');
return { json: result };
```

## Performance Optimization {#performance}

### 1. Batch Processing

```javascript
// Bad: Sync 1 record at a time
for (const record of records) {
  await db.insert(record); // 10,000 records = 10,000 queries!
}

// Good: Batch insert
const BATCH_SIZE = 1000;
for (let i = 0; i < records.length; i += BATCH_SIZE) {
  const batch = records.slice(i, i + BATCH_SIZE);
  await db.insertMany(batch); // 10,000 records = 10 queries
}
```

**n8n Implementation:**
```javascript
// Split Node
Mode: Split Into Batches
Batch Size: 1000

// Process each batch
Loop ‚Üí Insert batch ‚Üí Next batch
```

### 2. Parallel Processing

```javascript
// Split into multiple workflows
// Workflow 1: Sync users (1-10000)
// Workflow 2: Sync users (10001-20000)
// Workflow 3: Sync users (20001-30000)

// Run all in parallel
```

### 3. Incremental Sync

```javascript
// Track last sync time
// Only query new/updated records

SELECT * FROM products
WHERE updated_at > '2025-01-01 10:00:00'
ORDER BY updated_at ASC
LIMIT 1000

// Much faster than full table scan
```

### 4. Indexes

```sql
-- Create indexes on sync columns
CREATE INDEX idx_updated_at ON products(updated_at);
CREATE INDEX idx_id ON products(id);

-- Query will be 10-100x faster
```

### 5. Use COPY (PostgreSQL)

```javascript
// INSERT: ~5,000 rows/sec
// COPY: ~50,000+ rows/sec

// n8n: Use "Execute Query" with COPY command
COPY products (id, name, price)
FROM STDIN WITH (FORMAT CSV)
```

### 6. Connection Pooling

```javascript
// Reuse database connections
// n8n does this automatically

// But limit concurrent connections:
Max Connections: 10 (adjust based on DB capacity)
```

## Monitoring & Error Handling {#monitoring}

### 1. Sync Metadata Table

```sql
CREATE TABLE sync_runs (
  id SERIAL PRIMARY KEY,
  source TEXT,
  destination TEXT,
  started_at TIMESTAMP,
  completed_at TIMESTAMP,
  records_processed INT,
  records_failed INT,
  status TEXT,
  error_message TEXT
);
```

**Log Every Run:**
```javascript
// PostgreSQL Node
INSERT INTO sync_runs (source, destination, started_at, status)
VALUES ('mysql', 'postgres', NOW(), 'running')
RETURNING id

// Store run_id for later updates

// At end:
UPDATE sync_runs
SET completed_at = NOW(),
    records_processed = :count,
    status = 'success'
WHERE id = :run_id
```

### 2. Error Handling

```javascript
// Try-Catch workflow structure

Try:
  ‚Üí Extract data
  ‚Üí Transform
  ‚Üí Load

Catch (Error):
  ‚Üí Log error to database
  ‚Üí Send alert (Slack/Email)
  ‚Üí (Optional) Retry logic

Finally:
  ‚Üí Update sync metadata
  ‚Üí Clean up temp data
```

### 3. Alerts & Notifications

```javascript
// Slack Node - Alert on failure
Channel: #data-alerts
Message:
‚ö†Ô∏è Database Sync Failed!

Source: MySQL
Destination: PostgreSQL
Error: {{ $json.error }}
Time: {{ $now }}
Records Processed: {{ $json.recordsProcessed }}

[View Logs] [Retry Sync]
```

### 4. Dashboard

```javascript
// Daily Report to Google Sheets

Sync Summary - {{ $today }}
---
Total Runs: {{ $json.totalRuns }}
Successful: {{ $json.successful }}
Failed: {{ $json.failed }}
Records Synced: {{ $json.totalRecords }}

Top Errors:
1. {{ $json.topErrors[0] }}
2. {{ $json.topErrors[1] }}
```

## Security Best Practices {#security}

### 1. Credentials Management

```javascript
// ‚úÖ DO: Use n8n credentials store
// Encrypted at rest
// Never in workflow JSON

// ‚ùå DON'T: Hardcode passwords in workflows
password: 'mypassword123' // NEVER!

// ‚úÖ DO:
password: {{ $credentials.mysql.password }}
```

### 2. Read-only Source Accounts

```sql
-- Create read-only user for source DB
CREATE USER 'sync_user'@'%' IDENTIFIED BY 'strong_password';
GRANT SELECT ON database.* TO 'sync_user'@'%';

-- Prevents accidental writes to production
```

### 3. Network Security

```javascript
// Use VPN or SSH tunnel for databases
// Don't expose databases publicly

// n8n Cloud ‚Üí VPN ‚Üí Private Database
// Or: SSH tunnel
ssh -L 3306:localhost:3306 user@db-server
```

### 4. Data Masking

```javascript
// Mask sensitive data during sync

// Code Node
const items = $input.all();

items.forEach(item => {
  // Mask email
  item.json.email = maskEmail(item.json.email);
  // user@example.com ‚Üí u***@e***.com

  // Mask phone
  item.json.phone = maskPhone(item.json.phone);
  // 0812345678 ‚Üí 081***5678

  // Remove sensitive fields
  delete item.json.password;
  delete item.json.ssn;
});

return items;
```

### 5. Audit Logs

```javascript
// Log all sync operations
INSERT INTO audit_log (
  action,
  source_table,
  record_id,
  user,
  timestamp,
  changes
) VALUES (
  'sync',
  'products',
  123,
  'n8n_sync_user',
  NOW(),
  '{"price": {"old": 100, "new": 120}}'
)
```

## ‡∏Å‡∏£‡∏ì‡∏µ‡∏®‡∏∂‡∏Å‡∏©‡∏≤: E-commerce Platform {#case-study}

### ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó: Multi-channel E-commerce

**‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå:**
- ‡∏Ç‡∏≤‡∏¢‡∏ö‡∏ô Shopify, LINE Shopping, Facebook Shop
- ‡πÉ‡∏ä‡πâ Airtable ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (marketing team)
- ‡∏°‡∏µ PostgreSQL ‡πÄ‡∏õ‡πá‡∏ô main database
- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Google Sheets ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö finance team

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:**
- ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏™‡∏ï‡πá‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏µ‡πà
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô ‚Üí ‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏´‡∏°‡∏î‡∏™‡∏ï‡πá‡∏≠‡∏Å
- Finance ‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ real-time

**Solution ‡∏î‡πâ‡∏ß‡∏¢ n8n:**

```
                    n8n Central Hub
                          |
        /-----------------+------------------\
        |                 |                  |
   PostgreSQL         Airtable         Google Sheets
   (Master DB)      (Marketing)         (Finance)
        |                                    |
  /-----+-----\                         Shopify
Shopify  LINE                          Dashboard
         Shopping
```

**Workflows:**

**1. Product Sync (Bi-directional)**
```javascript
// Airtable ‚Üî PostgreSQL
// Real-time via webhooks

Airtable change ‚Üí n8n webhook
    ‚Üì
Check PostgreSQL
    ‚Üì
If Airtable newer ‚Üí Update PostgreSQL
    ‚Üì
Sync to Shopify, LINE Shopping

// Reverse:
PostgreSQL change (from app) ‚Üí Webhook ‚Üí Update Airtable
```

**2. Stock Sync (Real-time)**
```javascript
// Shopify order ‚Üí Reduce stock everywhere

Shopify Webhook: Order Created
    ‚Üì
Get product_id, quantity
    ‚Üì
PostgreSQL: UPDATE products SET stock = stock - quantity
    ‚Üì
Airtable: Update stock
    ‚Üì
LINE Shopping API: Update stock
    ‚Üì
Slack: Alert if stock < 10
```

**3. Sales Dashboard (Scheduled)**
```javascript
// Every hour: Sync sales to Google Sheets

Schedule: Every hour
    ‚Üì
PostgreSQL: Get orders from last hour
    ‚Üì
Calculate: revenue, orders count, avg order value
    ‚Üì
Google Sheets: Append row to "Hourly Sales"
    ‚Üì
Finance team sees real-time dashboard
```

**4. Inventory Sync (Nightly)**
```javascript
// 2 AM: Full inventory reconciliation

Schedule: Daily 2 AM
    ‚Üì
Get inventory from:
  - Shopify
  - LINE Shopping
  - PostgreSQL
    ‚Üì
Compare and detect discrepancies
    ‚Üì
Alert if differences > 5%
    ‚Üì
Auto-fix minor discrepancies
    ‚Üì
Generate report
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

üìä **99.8% stock accuracy** (‡∏à‡∏≤‡∏Å 85%)
‚è±Ô∏è **Real-time sync** (‡∏à‡∏≤‡∏Å manual daily)
üí∞ **‡∏•‡∏î overselling 95%** (‡∏à‡∏≤‡∏Å 20 cases/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‚Üí 1 case/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)
üòä **Customer satisfaction ‚Üë 30%**
‚è±Ô∏è **Save 15 ‡∏ä‡∏°./‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå** (no manual sync)
üíµ **ROI: 1,200%** (‡∏•‡∏á‡∏ó‡∏∏‡∏ô n8n $20/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô, ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î+‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏° $240/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)

## FAQ {#faq}

### Q1: Real-time sync ‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏°?

**A:** ‡πÑ‡∏î‡πâ! ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á setup ‡∏ñ‡∏π‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ

**Options:**
1. **Database Triggers + Webhooks** (latency < 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
2. **CDC tools** (Debezium, latency ~1-5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
3. **Polling ‡∏ó‡∏∏‡∏Å 10-30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ** (quasi-real-time)

**‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** Triggers + Webhooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö critical data

### Q2: Sync database ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°?

**A:** ‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ strategies:

**< 10,000 rows:** Full sync ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
**10,000 - 100,000:** Incremental sync
**100,000 - 1M:** Batch + parallel processing
**> 1M:** CDC tools + data partitioning

### Q3: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ schema changes ‡∏¢‡∏±‡∏á‡πÑ‡∏á?

**A:** Planning + versioning

```javascript
// ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà:

1. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô destination (allow NULL)
2. ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó n8n workflow (map ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà)
3. Backfill data ‡πÄ‡∏Å‡πà‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
4. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô source (‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡∏Å‡πà‡∏≠‡∏ô)

// ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:
1. ‡∏´‡∏¢‡∏∏‡∏î sync ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ô n8n
2. ‡∏•‡∏ö‡∏à‡∏≤‡∏Å source
3. (Optional) ‡∏•‡∏ö‡∏à‡∏≤‡∏Å destination ‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á
```

### Q4: Handle data types ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?

**A:** Transform ‡πÉ‡∏ô Code Node

```javascript
// MySQL ‚Üí PostgreSQL
// TINYINT(1) ‚Üí BOOLEAN
is_active: item.json.is_active === 1

// DECIMAL ‚Üí NUMERIC
price: parseFloat(item.json.price)

// DATETIME ‚Üí TIMESTAMPTZ
created_at: new Date(item.json.created_at).toISOString()

// JSON string ‚Üí JSON object
metadata: JSON.parse(item.json.metadata)
```

### Q5: ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?

**n8n Setup:**
```
n8n self-hosted: ‡∏ü‡∏£‡∏µ + VPS $10/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
n8n Cloud: $20-50/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
```

**Database costs:**
```
‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö provider:
- Supabase: ‡∏ü‡∏£‡∏µ (500MB)
- AWS RDS: ~$15/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (small instance)
- Google Cloud SQL: ~$10/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
- MongoDB Atlas: ‡∏ü‡∏£‡∏µ (512MB)
```

**Total:** $10-70/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (depends on setup)

### Q6: ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÑ‡∏´‡∏°?

**A:** ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‡∏ñ‡πâ‡∏≤‡∏ó‡∏≥‡∏ñ‡∏π‡∏Å:

‚úÖ ‡πÉ‡∏ä‡πâ read-only credentials ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö source
‚úÖ Encrypt credentials ‡πÉ‡∏ô n8n
‚úÖ Use VPN/SSH tunnel
‚úÖ Audit logs
‚úÖ ‡πÑ‡∏°‡πà sync sensitive data (passwords, etc.)

## ‡∏™‡∏£‡∏∏‡∏õ {#conclusion}

Database Sync ‡∏î‡πâ‡∏ß‡∏¢ n8n ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ synchronized ‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤ ‡∏•‡∏î‡∏á‡∏≤‡∏ô manual ‡πÅ‡∏•‡∏∞ errors

### ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏´‡∏•‡∏±‡∏Å

‚úÖ **Real-time or scheduled sync** ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
‚úÖ **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢ databases** (SQL, NoSQL, Spreadsheets)
‚úÖ **Flexible** customizable logic
‚úÖ **Cost-effective** ‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ enterprise ETL tools
‚úÖ **Easy monitoring** tracking + alerts

### ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£

1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å sync strategy (real-time/scheduled)
2. Setup n8n + database connections
3. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å simple sync workflow
4. ‡πÄ‡∏û‡∏¥‡πà‡∏° error handling + monitoring
5. Scale up ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

### Next Steps

- [Download Sync Workflow Templates](https://example.com)
- [Database Schema Examples](https://example.com)
- [Video Tutorial](https://youtube.com)

---

### ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

- [n8n CRM Automation](/blog/n8n-crm-automation/)
- [n8n Email Marketing Automation](/blog/n8n-email-marketing/)
- [Zapier vs n8n vs Make](/blog/zapier-vs-n8n-vs-make/)
- [AI Data Analysis ‡∏Å‡∏±‡∏ö Google Sheets](/blog/ai-data-analysis-spreadsheet/)
- [‡∏Ñ‡∏≠‡∏£‡πå‡∏™ AI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô](/blog/ai-prompt-writing-techniques/)

---

**‡∏™‡∏ô‡πÉ‡∏à‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≠‡∏£‡πå‡∏™ n8n Automation?** ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö database sync ‡πÅ‡∏•‡∏∞ automation ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤
üëâ [‡∏î‡∏π‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå](https://aiunlock.co/) | [‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°](/contact/)
